{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8b3c19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "from transformers import XLNetTokenizer, XLNetModel, AdamW, get_linear_schedule_with_warmup\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import *\n",
    "from sklearn.utils import shuffle\n",
    "from collections import defaultdict\n",
    "from textwrap import wrap\n",
    "from pylab import rcParams\n",
    "import re\n",
    "\n",
    "from torch import nn, optim\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from torch.utils.data import TensorDataset,RandomSampler,SequentialSampler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2449bef2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2ac6d952210>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RANDOM_SEED = 69\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d20245be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c14a542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading data using pandas\n",
    "path_to_data = \"Crypto_Sentiment_Dataset.csv\"\n",
    "df = pd.read_csv(path_to_data, encoding = 'raw_unicode_escape', engine ='python',header = None)\n",
    "\n",
    "# Shuffle and Clip data\n",
    "df = shuffle(df)\n",
    "#df = df[:20000]\n",
    "\n",
    "# Function to clean text. Remove tagged entities, hyperlinks, emojis\n",
    "def clean_text(text):\n",
    "    text = re.sub(r\"@[A-Za-z0-9]+\", ' ', text)\n",
    "    text = re.sub(r\"https?://[A-Za-z0-9./]+\", ' ', text)\n",
    "    text = re.sub(r\"[^a-zA-z.!?'0-9]\", ' ', text)\n",
    "    text = re.sub('\\t', ' ',  text)\n",
    "    text = re.sub(r\" +\", ' ', text)\n",
    "    return text\n",
    " \n",
    "df['tweet'] = df[3].apply(clean_text)\n",
    "\n",
    "# Function to convert labels to number.\n",
    "def sentiment2label(sentiment):\n",
    "    if sentiment == \"Positive\":\n",
    "        return 1\n",
    "    else :\n",
    "        return 0\n",
    "\n",
    "df['sentiment'] = df[4].apply(sentiment2label)\n",
    "\n",
    "# List of class names.\n",
    "class_names = ['negative', 'positive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec76647b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    302\n",
       "0    261\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c6a48ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "563\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>QQYCQPQK6WFA</td>\n",
       "      <td>false</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cryptocurrency is bad for the environment beca...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>https://www.reddit.com/r/explainlikeimfive/com...</td>\n",
       "      <td>Cryptocurrency is bad for the environment beca...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>ADCXHGCQRA34</td>\n",
       "      <td>false</td>\n",
       "      <td>NaN</td>\n",
       "      <td>It's great to get paid for heating a swimming ...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>https://www.reddit.com/r/Bitcoin/comments/uzzp...</td>\n",
       "      <td>It's great to get paid for heating a swimming ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>WYWGJAYCCA6D</td>\n",
       "      <td>false</td>\n",
       "      <td>NaN</td>\n",
       "      <td>This is the way. Until the ride back up, go ou...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>https://www.reddit.com/r/Bitcoin/comments/ul5y...</td>\n",
       "      <td>This is the way. Until the ride back up go out...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>AQDRYYFGDJJ7</td>\n",
       "      <td>false</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I donât have the money to invest in it but I...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>https://www.reddit.com/r/AskWomen/comments/s36...</td>\n",
       "      <td>I don t have the money to invest in it but I d...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>TD36G7T2EZEK</td>\n",
       "      <td>false</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Literally crashing to zero in real time atm, L...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>https://old.reddit.com/r/terraluna/comments/un...</td>\n",
       "      <td>Literally crashing to zero in real time atm Lu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>3796EY394VG3</td>\n",
       "      <td>false</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Another arrogant prick with an algorithmic sta...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>https://www.reddit.com/r/CryptoCurrency/commen...</td>\n",
       "      <td>Another arrogant prick with an algorithmic sta...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>GAN44MJMXW36</td>\n",
       "      <td>false</td>\n",
       "      <td>NaN</td>\n",
       "      <td>just buy it now and forget about it.\\n\\ntrust ...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>https://www.reddit.com/r/Bitcoin/comments/ly8z...</td>\n",
       "      <td>just buy it now and forget about it. trust the...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>RZ974APDDTJY</td>\n",
       "      <td>false</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Basically how the ponzi falls. Sure Luna has h...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>https://www.reddit.com/r/CryptoCurrency/commen...</td>\n",
       "      <td>Basically how the ponzi falls. Sure Luna has h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>XKEQPPFJWHY9</td>\n",
       "      <td>false</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Price-wise, I think it's a good time to get in...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>https://www.reddit.com/r/CryptoCurrency/commen...</td>\n",
       "      <td>Price wise I think it's a good time to get int...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>GWXY3F6YGEPK</td>\n",
       "      <td>false</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bitcoin just had a headstart, and it's issuanc...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>https://www.reddit.com/r/ethereum/comments/uze...</td>\n",
       "      <td>Bitcoin just had a headstart and it's issuance...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>KHP239VPK9M3</td>\n",
       "      <td>false</td>\n",
       "      <td>NaN</td>\n",
       "      <td>His first company ticket monster was a major f...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>https://www.reddit.com/r/CryptoCurrency/commen...</td>\n",
       "      <td>His first company ticket monster was a major f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>7G7NZEEGPR4K</td>\n",
       "      <td>false</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Crypto is a fad. Crypto underlying value is ze...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>https://www.reddit.com/r/Bogleheads/comments/s...</td>\n",
       "      <td>Crypto is a fad. Crypto underlying value is ze...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>6XFJ6ADHNKEZ</td>\n",
       "      <td>false</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ETH is Great but .... Matic is the Way</td>\n",
       "      <td>Positive</td>\n",
       "      <td>https://www.reddit.com/r/CryptoCurrency/commen...</td>\n",
       "      <td>ETH is Great but .... Matic is the Way</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>WXXW646EHXPR</td>\n",
       "      <td>false</td>\n",
       "      <td>NaN</td>\n",
       "      <td>If going long term, BTC and ETH are the coins ...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>https://www.reddit.com/r/CryptoCurrency/commen...</td>\n",
       "      <td>If going long term BTC and ETH are the coins t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ï»¿worker_id</td>\n",
       "      <td>is_reviewed</td>\n",
       "      <td>review_score</td>\n",
       "      <td>Comment Text</td>\n",
       "      <td>Sentiment</td>\n",
       "      <td>Reddit URL</td>\n",
       "      <td>Comment Text</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>4VHD44T9YCQ4</td>\n",
       "      <td>false</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Elon was the reason Doge was on a perpetual di...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>https://www.reddit.com/r/dogecoin/comments/ux6...</td>\n",
       "      <td>Elon was the reason Doge was on a perpetual di...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>VDCA2EXAVGNA</td>\n",
       "      <td>false</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10% was unlocked for developers. This dude is ...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>https://www.reddit.com/r/CryptoCurrency/commen...</td>\n",
       "      <td>10 was unlocked for developers. This dude is s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>MTCJYTYKKHZJ</td>\n",
       "      <td>false</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Massive ecosystem. Pretty much all application...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>https://www.reddit.com/r/CryptoCurrency/commen...</td>\n",
       "      <td>Massive ecosystem. Pretty much all application...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>VME4939DFDXR</td>\n",
       "      <td>false</td>\n",
       "      <td>NaN</td>\n",
       "      <td>It's going to dump you smooth brain</td>\n",
       "      <td>Negative</td>\n",
       "      <td>https://www.reddit.com/r/terraluna/comments/v0...</td>\n",
       "      <td>It's going to dump you smooth brain</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>6CNHTCG6W6XM</td>\n",
       "      <td>false</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I'm in crypto since 2012 and so far I found no...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>https://www.reddit.com/r/CryptoCurrency/commen...</td>\n",
       "      <td>I'm in crypto since 2012 and so far I found no...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0            1             2  \\\n",
       "343  QQYCQPQK6WFA        false           NaN   \n",
       "381  ADCXHGCQRA34        false           NaN   \n",
       "135  WYWGJAYCCA6D        false           NaN   \n",
       "222  AQDRYYFGDJJ7        false           NaN   \n",
       "20   TD36G7T2EZEK        false           NaN   \n",
       "386  3796EY394VG3        false           NaN   \n",
       "550  GAN44MJMXW36        false           NaN   \n",
       "480  RZ974APDDTJY        false           NaN   \n",
       "430  XKEQPPFJWHY9        false           NaN   \n",
       "307  GWXY3F6YGEPK        false           NaN   \n",
       "7    KHP239VPK9M3        false           NaN   \n",
       "500  7G7NZEEGPR4K        false           NaN   \n",
       "17   6XFJ6ADHNKEZ        false           NaN   \n",
       "150  WXXW646EHXPR        false           NaN   \n",
       "0    ï»¿worker_id  is_reviewed  review_score   \n",
       "216  4VHD44T9YCQ4        false           NaN   \n",
       "207  VDCA2EXAVGNA        false           NaN   \n",
       "561  MTCJYTYKKHZJ        false           NaN   \n",
       "354  VME4939DFDXR        false           NaN   \n",
       "490  6CNHTCG6W6XM        false           NaN   \n",
       "\n",
       "                                                     3          4  \\\n",
       "343  Cryptocurrency is bad for the environment beca...   Negative   \n",
       "381  It's great to get paid for heating a swimming ...   Positive   \n",
       "135  This is the way. Until the ride back up, go ou...   Positive   \n",
       "222  I donât have the money to invest in it but I...   Positive   \n",
       "20   Literally crashing to zero in real time atm, L...   Negative   \n",
       "386  Another arrogant prick with an algorithmic sta...   Negative   \n",
       "550  just buy it now and forget about it.\\n\\ntrust ...   Positive   \n",
       "480  Basically how the ponzi falls. Sure Luna has h...   Negative   \n",
       "430  Price-wise, I think it's a good time to get in...   Positive   \n",
       "307  Bitcoin just had a headstart, and it's issuanc...   Positive   \n",
       "7    His first company ticket monster was a major f...   Negative   \n",
       "500  Crypto is a fad. Crypto underlying value is ze...   Negative   \n",
       "17              ETH is Great but .... Matic is the Way   Positive   \n",
       "150  If going long term, BTC and ETH are the coins ...   Positive   \n",
       "0                                         Comment Text  Sentiment   \n",
       "216  Elon was the reason Doge was on a perpetual di...   Negative   \n",
       "207  10% was unlocked for developers. This dude is ...   Negative   \n",
       "561  Massive ecosystem. Pretty much all application...   Positive   \n",
       "354                It's going to dump you smooth brain   Negative   \n",
       "490  I'm in crypto since 2012 and so far I found no...   Negative   \n",
       "\n",
       "                                                     5  \\\n",
       "343  https://www.reddit.com/r/explainlikeimfive/com...   \n",
       "381  https://www.reddit.com/r/Bitcoin/comments/uzzp...   \n",
       "135  https://www.reddit.com/r/Bitcoin/comments/ul5y...   \n",
       "222  https://www.reddit.com/r/AskWomen/comments/s36...   \n",
       "20   https://old.reddit.com/r/terraluna/comments/un...   \n",
       "386  https://www.reddit.com/r/CryptoCurrency/commen...   \n",
       "550  https://www.reddit.com/r/Bitcoin/comments/ly8z...   \n",
       "480  https://www.reddit.com/r/CryptoCurrency/commen...   \n",
       "430  https://www.reddit.com/r/CryptoCurrency/commen...   \n",
       "307  https://www.reddit.com/r/ethereum/comments/uze...   \n",
       "7    https://www.reddit.com/r/CryptoCurrency/commen...   \n",
       "500  https://www.reddit.com/r/Bogleheads/comments/s...   \n",
       "17   https://www.reddit.com/r/CryptoCurrency/commen...   \n",
       "150  https://www.reddit.com/r/CryptoCurrency/commen...   \n",
       "0                                           Reddit URL   \n",
       "216  https://www.reddit.com/r/dogecoin/comments/ux6...   \n",
       "207  https://www.reddit.com/r/CryptoCurrency/commen...   \n",
       "561  https://www.reddit.com/r/CryptoCurrency/commen...   \n",
       "354  https://www.reddit.com/r/terraluna/comments/v0...   \n",
       "490  https://www.reddit.com/r/CryptoCurrency/commen...   \n",
       "\n",
       "                                                 tweet  sentiment  \n",
       "343  Cryptocurrency is bad for the environment beca...          0  \n",
       "381  It's great to get paid for heating a swimming ...          1  \n",
       "135  This is the way. Until the ride back up go out...          1  \n",
       "222  I don t have the money to invest in it but I d...          1  \n",
       "20   Literally crashing to zero in real time atm Lu...          0  \n",
       "386  Another arrogant prick with an algorithmic sta...          0  \n",
       "550  just buy it now and forget about it. trust the...          1  \n",
       "480  Basically how the ponzi falls. Sure Luna has h...          0  \n",
       "430  Price wise I think it's a good time to get int...          1  \n",
       "307  Bitcoin just had a headstart and it's issuance...          1  \n",
       "7    His first company ticket monster was a major f...          0  \n",
       "500  Crypto is a fad. Crypto underlying value is ze...          0  \n",
       "17              ETH is Great but .... Matic is the Way          1  \n",
       "150  If going long term BTC and ETH are the coins t...          1  \n",
       "0                                         Comment Text          0  \n",
       "216  Elon was the reason Doge was on a perpetual di...          0  \n",
       "207  10 was unlocked for developers. This dude is s...          0  \n",
       "561  Massive ecosystem. Pretty much all application...          1  \n",
       "354                It's going to dump you smooth brain          0  \n",
       "490  I'm in crypto since 2012 and so far I found no...          0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(df))\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38fa0f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import XLNetTokenizer, XLNetModel\n",
    "PRE_TRAINED_MODEL_NAME = 'xlnet-base-cased'\n",
    "tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a7a6270",
   "metadata": {},
   "outputs": [],
   "source": [
    "class tweetDataset(Dataset):\n",
    "\n",
    "    def __init__(self, tweets, targets, tokenizer, max_len):\n",
    "        self.tweets = tweets\n",
    "        self.targets = targets\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.tweets)\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        tweet = str(self.tweets[item])\n",
    "        target = self.targets[item]\n",
    "\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "        tweet,\n",
    "        add_special_tokens=True,\n",
    "        max_length=self.max_len,\n",
    "        return_token_type_ids=False,\n",
    "        pad_to_max_length=False,\n",
    "        return_attention_mask=True,\n",
    "        return_tensors='pt',\n",
    "        )\n",
    "\n",
    "        input_ids = pad_sequences(encoding['input_ids'], maxlen=MAX_LEN, dtype=torch.Tensor ,truncating=\"post\",padding=\"post\")\n",
    "        input_ids = input_ids.astype(dtype = 'int64')\n",
    "        input_ids = torch.tensor(input_ids) \n",
    "\n",
    "        attention_mask = pad_sequences(encoding['attention_mask'], maxlen=MAX_LEN, dtype=torch.Tensor ,truncating=\"post\",padding=\"post\")\n",
    "        attention_mask = attention_mask.astype(dtype = 'int64')\n",
    "        attention_mask = torch.tensor(attention_mask)       \n",
    "\n",
    "        return {\n",
    "        'tweet': tweet,\n",
    "        'input_ids': input_ids,\n",
    "        'attention_mask': attention_mask.flatten(),\n",
    "        'targets': torch.tensor(target, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8b15cc1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((281, 8), (141, 8), (141, 8))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train, df_test = train_test_split(df, test_size=0.5, random_state=101)\n",
    "df_val, df_test = train_test_split(df_test, test_size=0.5, random_state=101)\n",
    "df_train.shape, df_val.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0399e089",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_data_loader(df, tokenizer, max_len, batch_size):\n",
    "  ds = tweetDataset(\n",
    "    tweets=df.tweet.to_numpy(),\n",
    "    targets=df.sentiment.to_numpy(),\n",
    "    tokenizer=tokenizer,\n",
    "    max_len=max_len\n",
    "  )\n",
    "\n",
    "  return DataLoader(\n",
    "    ds,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=0\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7327ad1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 2\n",
    "MAX_LEN = 1024\n",
    "train_data_loader = create_data_loader(df_train, tokenizer, MAX_LEN, BATCH_SIZE)\n",
    "val_data_loader = create_data_loader(df_val, tokenizer, MAX_LEN, BATCH_SIZE)\n",
    "test_data_loader = create_data_loader(df_test, tokenizer, MAX_LEN, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "646e7463",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n",
      "- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['sequence_summary.summary.weight', 'logits_proj.weight', 'logits_proj.bias', 'sequence_summary.summary.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import XLNetForSequenceClassification\n",
    "model = XLNetForSequenceClassification.from_pretrained('xlnet-base-cased', num_labels = 2)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c2c4522",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XLNetForSequenceClassification(\n",
       "  (transformer): XLNetModel(\n",
       "    (word_embedding): Embedding(32000, 768)\n",
       "    (layer): ModuleList(\n",
       "      (0): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (activation_function): GELUActivation()\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (1): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (activation_function): GELUActivation()\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (2): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (activation_function): GELUActivation()\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (3): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (activation_function): GELUActivation()\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (4): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (activation_function): GELUActivation()\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (5): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (activation_function): GELUActivation()\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (6): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (activation_function): GELUActivation()\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (7): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (activation_function): GELUActivation()\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (8): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (activation_function): GELUActivation()\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (9): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (activation_function): GELUActivation()\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (10): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (activation_function): GELUActivation()\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (11): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (activation_function): GELUActivation()\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (sequence_summary): SequenceSummary(\n",
       "    (summary): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "    (first_dropout): Identity()\n",
       "    (last_dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (logits_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "88562961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "EPOCHS = 6\n",
    "BATCH_SIZE = 2\n",
    "\n",
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "                                {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "                                {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay':0.0}\n",
    "]\n",
    "optimizer = torch.optim.AdamW(optimizer_grouped_parameters, lr=3e-5)\n",
    "#optimizer = AdamW(optimizer_grouped_parameters, lr=3e-5)\n",
    "\n",
    "total_steps = len(train_data_loader) * EPOCHS\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "  optimizer,\n",
    "  num_warmup_steps=0,\n",
    "  num_training_steps=total_steps\n",
    ")\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cf91face",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['tweet', 'input_ids', 'attention_mask', 'targets'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = next(iter(val_data_loader))\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "321a31ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 1024])\n"
     ]
    }
   ],
   "source": [
    "input_ids = data['input_ids'].to(device)\n",
    "attention_mask = data['attention_mask'].to(device)\n",
    "targets = data['targets'].to(device)\n",
    "print(input_ids.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "069a1d19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1024])\n",
      "torch.Size([2, 1024])\n"
     ]
    }
   ],
   "source": [
    "print(input_ids.reshape(BATCH_SIZE,1024).shape) # batch size x seq length\n",
    "print(attention_mask.shape) # batch size x seq length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "391d134d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[9961,   56, 3429,  ...,    0,    0,    0]], device='cuda:0')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f7bab8ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XLNetForSequenceClassificationOutput(loss=tensor(0.7754, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 0.0097,  0.1364],\n",
       "        [ 0.2492, -0.1607]], device='cuda:0', grad_fn=<AddmmBackward0>), mems=(tensor([[[ 0.0372,  0.0792, -0.0861,  ...,  0.0489,  0.0098, -0.0162],\n",
       "         [-0.0179, -0.0364, -0.0415,  ...,  0.0125,  0.0062,  0.0325]],\n",
       "\n",
       "        [[-0.0482, -0.0126,  0.0453,  ..., -0.0780, -0.0425,  0.0127],\n",
       "         [-0.0004, -0.0517,  0.0827,  ...,  0.0242,  0.0469,  0.0494]],\n",
       "\n",
       "        [[ 0.0818, -0.0357, -0.0359,  ...,  0.0127, -0.0032,  0.0021],\n",
       "         [-0.0027, -0.0376,  0.0661,  ...,  0.0254,  0.0216,  0.0054]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.0049,  0.0655, -0.0151,  ..., -0.0458, -0.0061,  0.0346],\n",
       "         [-0.0049,  0.0655, -0.0151,  ..., -0.0458, -0.0061,  0.0346]],\n",
       "\n",
       "        [[-0.0049,  0.0655, -0.0151,  ..., -0.0458, -0.0061,  0.0346],\n",
       "         [-0.0049,  0.0655, -0.0151,  ..., -0.0458, -0.0061,  0.0346]],\n",
       "\n",
       "        [[-0.0049,  0.0655, -0.0151,  ..., -0.0458, -0.0061,  0.0346],\n",
       "         [-0.0049,  0.0655, -0.0151,  ..., -0.0458, -0.0061,  0.0346]]],\n",
       "       device='cuda:0'), tensor([[[ 1.3236e+00,  1.2894e+00, -9.7838e-01,  ..., -6.0529e-01,\n",
       "          -3.9784e-02, -6.6152e-01],\n",
       "         [-4.1890e-01, -4.8759e-01, -1.0129e+00,  ...,  2.3881e-01,\n",
       "          -9.0521e-02,  9.1153e-01]],\n",
       "\n",
       "        [[-2.1880e-01,  2.4489e-01,  3.8524e-01,  ..., -2.4495e+00,\n",
       "          -5.5243e-01, -1.0183e-01],\n",
       "         [ 1.1004e+00, -1.2776e+00,  1.2619e+00,  ...,  5.2303e-01,\n",
       "           1.0384e+00,  8.4881e-01]],\n",
       "\n",
       "        [[ 2.1146e+00, -1.5694e-01, -2.1297e-01,  ..., -2.4073e-01,\n",
       "          -5.3192e-01, -9.2791e-01],\n",
       "         [ 7.4195e-01, -1.1632e+00,  1.7326e+00,  ...,  3.2556e-01,\n",
       "           4.7545e-01,  5.2764e-02]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 2.8262e-01,  2.0781e+00,  2.3321e-02,  ..., -9.9764e-01,\n",
       "          -1.5027e+00,  6.1020e-01],\n",
       "         [ 3.5527e-01,  2.0227e+00,  5.2543e-02,  ..., -7.2430e-01,\n",
       "          -1.1915e+00,  6.9322e-01]],\n",
       "\n",
       "        [[ 2.6737e-01,  2.0611e+00,  1.5730e-02,  ..., -9.9741e-01,\n",
       "          -1.4996e+00,  5.9977e-01],\n",
       "         [ 3.5552e-01,  1.9952e+00,  1.9713e-03,  ..., -6.3589e-01,\n",
       "          -1.1090e+00,  6.9411e-01]],\n",
       "\n",
       "        [[ 2.5244e-01,  2.0432e+00,  2.3691e-02,  ..., -1.0154e+00,\n",
       "          -1.4969e+00,  6.0273e-01],\n",
       "         [ 3.9847e-01,  1.9934e+00, -2.2506e-02,  ..., -5.7417e-01,\n",
       "          -1.0532e+00,  6.8034e-01]]], device='cuda:0'), tensor([[[ 1.1122e+00,  6.9818e-01, -3.7896e-01,  ...,  7.3466e-02,\n",
       "           4.4339e-02, -6.0354e-01],\n",
       "         [-3.3718e-01, -4.0643e-01, -1.0923e+00,  ...,  7.1258e-01,\n",
       "          -1.4804e-01,  1.0283e+00]],\n",
       "\n",
       "        [[ 1.1999e-02,  6.4607e-01,  1.3732e+00,  ..., -1.6568e+00,\n",
       "          -1.6716e-02,  1.5617e-01],\n",
       "         [ 5.9112e-01, -7.6399e-01,  1.4939e+00,  ...,  9.1163e-01,\n",
       "           1.5774e-01,  4.6587e-02]],\n",
       "\n",
       "        [[ 1.2944e+00, -4.3745e-01,  5.1766e-01,  ...,  3.5948e-01,\n",
       "           1.8429e-01, -9.2388e-01],\n",
       "         [ 6.8660e-01, -1.5882e+00,  2.5047e+00,  ..., -1.0621e-01,\n",
       "           7.9496e-01, -2.0622e-03]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-3.9599e-01,  1.9323e+00,  8.0850e-01,  ...,  5.2581e-02,\n",
       "          -1.0472e+00,  4.6693e-01],\n",
       "         [ 5.0084e-02,  1.8251e+00,  6.3876e-01,  ..., -1.8382e-01,\n",
       "          -8.8230e-01,  5.1526e-01]],\n",
       "\n",
       "        [[-4.0668e-01,  1.9337e+00,  7.8264e-01,  ...,  6.1906e-02,\n",
       "          -1.0217e+00,  4.5634e-01],\n",
       "         [ 6.3222e-02,  1.7652e+00,  5.7462e-01,  ..., -1.2359e-01,\n",
       "          -8.9187e-01,  5.0442e-01]],\n",
       "\n",
       "        [[-4.2631e-01,  1.9268e+00,  7.9941e-01,  ...,  7.0011e-02,\n",
       "          -1.0039e+00,  4.3747e-01],\n",
       "         [ 3.5491e-02,  1.7546e+00,  6.2901e-01,  ..., -7.4081e-02,\n",
       "          -8.2624e-01,  5.2533e-01]]], device='cuda:0'), tensor([[[ 0.7895,  0.9044, -0.1038,  ..., -0.1878, -0.1175,  0.5512],\n",
       "         [-0.1880, -0.1677, -0.6256,  ...,  0.7255,  0.0975,  0.7348]],\n",
       "\n",
       "        [[ 0.2529,  0.9089,  1.1195,  ..., -2.0183, -0.2963, -0.2149],\n",
       "         [ 0.3190, -0.9459,  0.5486,  ...,  0.5360,  0.8310, -1.0048]],\n",
       "\n",
       "        [[ 0.3724, -0.3062, -0.2536,  ..., -0.0691,  0.8498, -0.3046],\n",
       "         [ 0.0492, -1.0528,  2.5873,  ...,  0.1303,  1.2271, -0.2235]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.1212,  3.2189,  0.6414,  ...,  0.6001, -1.6837,  0.2121],\n",
       "         [-0.2043,  2.5924,  0.7215,  ...,  0.6696, -1.1048,  0.4507]],\n",
       "\n",
       "        [[-0.1310,  3.2376,  0.6128,  ...,  0.6047, -1.6511,  0.2011],\n",
       "         [-0.2004,  2.5625,  0.5750,  ...,  0.7766, -1.1756,  0.5175]],\n",
       "\n",
       "        [[-0.1618,  3.2546,  0.6409,  ...,  0.6142, -1.6301,  0.1828],\n",
       "         [-0.2066,  2.4980,  0.5903,  ...,  0.8499, -1.1520,  0.6160]]],\n",
       "       device='cuda:0'), tensor([[[ 1.1767, -0.1748,  0.1742,  ...,  0.5514,  0.2776,  1.2101],\n",
       "         [ 0.5909, -0.0051, -0.8980,  ...,  0.8988,  0.3114,  1.0188]],\n",
       "\n",
       "        [[ 0.6516,  0.0369,  0.9721,  ..., -0.8014, -0.3099,  0.6716],\n",
       "         [ 0.8449, -0.0753,  0.2949,  ...,  0.9037,  0.7821, -0.2320]],\n",
       "\n",
       "        [[ 0.5069, -1.0809, -0.5403,  ...,  1.2396,  1.3769,  0.8533],\n",
       "         [ 0.6089, -1.2158,  1.4743,  ...,  0.4239,  0.8171,  0.3063]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.4810,  2.0071,  0.4631,  ...,  1.8166, -0.7232,  0.1045],\n",
       "         [ 0.2912,  2.1295,  0.3127,  ...,  1.2857, -0.4490,  0.9210]],\n",
       "\n",
       "        [[ 0.4788,  2.0205,  0.4474,  ...,  1.8040, -0.6868,  0.0885],\n",
       "         [ 0.3534,  2.1235,  0.2435,  ...,  1.4028, -0.5613,  0.9633]],\n",
       "\n",
       "        [[ 0.4351,  2.0559,  0.4726,  ...,  1.7863, -0.6549,  0.0920],\n",
       "         [ 0.4366,  2.0230,  0.3137,  ...,  1.3988, -0.4188,  1.0562]]],\n",
       "       device='cuda:0'), tensor([[[ 0.9935,  0.3363,  0.2130,  ...,  0.5785,  0.2870, -0.1359],\n",
       "         [ 0.5547, -0.0410, -0.4778,  ...,  0.2771, -0.1173,  0.1960]],\n",
       "\n",
       "        [[ 1.0664,  0.6315,  0.8512,  ..., -0.2869,  0.1073, -0.2850],\n",
       "         [ 0.7088,  0.2650,  0.3183,  ...,  0.4132,  0.1543, -0.9817]],\n",
       "\n",
       "        [[ 0.4092, -0.3669, -0.0590,  ...,  0.5431,  0.7902, -0.6806],\n",
       "         [ 0.6680, -0.5227,  1.1595,  ...,  0.1628,  0.3124, -0.6343]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.7469,  1.9028,  0.5189,  ...,  1.6522, -0.4571,  0.1981],\n",
       "         [ 0.5776,  1.7233,  0.3400,  ...,  0.8284, -0.2780,  0.7465]],\n",
       "\n",
       "        [[ 0.7283,  1.9222,  0.4948,  ...,  1.6466, -0.4160,  0.1581],\n",
       "         [ 0.6132,  1.7331,  0.2978,  ...,  0.9374, -0.3203,  0.6846]],\n",
       "\n",
       "        [[ 0.6569,  1.9555,  0.5267,  ...,  1.6495, -0.3694,  0.1288],\n",
       "         [ 0.6860,  1.6761,  0.3854,  ...,  0.9504, -0.2425,  0.7363]]],\n",
       "       device='cuda:0'), tensor([[[ 0.4489,  0.8410, -0.4811,  ...,  0.7247,  0.3022, -0.7000],\n",
       "         [ 0.5279,  0.2462, -0.5341,  ...,  0.6480, -0.2183,  0.5356]],\n",
       "\n",
       "        [[ 0.9868,  1.3380,  0.3160,  ..., -0.8440, -0.2237, -1.0916],\n",
       "         [ 0.3626,  0.6890,  0.2588,  ...,  1.2709,  0.1973, -0.8480]],\n",
       "\n",
       "        [[ 0.5227, -0.1749, -0.3755,  ...,  0.2760,  0.1585, -0.7259],\n",
       "         [ 0.7862, -0.3167,  0.8478,  ...,  0.2406,  0.7879, -0.6038]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.9444,  2.4947,  1.0828,  ...,  1.8052, -0.5250, -0.2173],\n",
       "         [ 0.8429,  2.0862,  0.5950,  ...,  1.3833,  0.5197,  0.0701]],\n",
       "\n",
       "        [[ 0.9454,  2.5074,  1.0731,  ...,  1.8069, -0.5069, -0.2990],\n",
       "         [ 0.8219,  2.1436,  0.4093,  ...,  1.3923,  0.3773,  0.0395]],\n",
       "\n",
       "        [[ 0.8901,  2.5354,  1.1377,  ...,  1.8163, -0.5066, -0.3683],\n",
       "         [ 0.8716,  2.1363,  0.5069,  ...,  1.4235,  0.4594,  0.0574]]],\n",
       "       device='cuda:0'), tensor([[[ 0.9978,  1.3218,  0.2910,  ..., -0.3408,  0.0510, -0.3394],\n",
       "         [ 0.4903,  0.0496, -0.2682,  ...,  0.3333,  0.3821,  0.5901]],\n",
       "\n",
       "        [[ 1.2194,  1.0839,  0.8126,  ..., -1.6947, -0.1784, -0.6346],\n",
       "         [ 0.1500,  0.6981,  0.5743,  ...,  1.1352,  0.5103, -0.3743]],\n",
       "\n",
       "        [[ 0.5679,  0.7606, -0.2807,  ..., -0.9817, -0.3606,  0.0625],\n",
       "         [ 0.3477, -0.3773,  1.5736,  ..., -0.1799,  0.7456,  0.4301]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.5504,  2.4311,  1.4151,  ...,  0.8442,  0.2595,  0.6335],\n",
       "         [ 0.6135,  2.0085,  0.7913,  ...,  0.8618,  0.6438, -0.4001]],\n",
       "\n",
       "        [[ 0.5645,  2.4293,  1.4088,  ...,  0.8117,  0.2560,  0.5749],\n",
       "         [ 0.7930,  2.1298,  0.7900,  ...,  1.0404,  0.4937, -0.3625]],\n",
       "\n",
       "        [[ 0.5374,  2.4591,  1.4481,  ...,  0.7875,  0.2294,  0.5194],\n",
       "         [ 0.8582,  2.1628,  0.9028,  ...,  1.0784,  0.5699, -0.3026]]],\n",
       "       device='cuda:0'), tensor([[[ 0.2638,  1.5395,  0.1488,  ..., -0.6227, -0.2183,  0.2025],\n",
       "         [ 0.8251,  0.1392, -0.1606,  ...,  0.2400,  0.1915,  0.6859]],\n",
       "\n",
       "        [[ 0.1394,  1.4440,  0.9602,  ..., -2.1456, -0.6452, -0.0806],\n",
       "         [ 0.6064,  0.5997,  0.2337,  ...,  0.7975,  0.1512, -0.7315]],\n",
       "\n",
       "        [[ 0.0837,  1.2746, -0.5368,  ..., -1.1961, -0.8836,  0.1590],\n",
       "         [ 0.1325, -0.3039,  1.3452,  ..., -0.3819,  0.8920,  0.1204]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.5638,  1.8374,  0.8929,  ...,  1.1669,  0.3384,  0.6221],\n",
       "         [ 0.5038,  1.7370,  0.8636,  ...,  0.0200,  0.2618, -0.7452]],\n",
       "\n",
       "        [[ 0.5631,  1.8166,  0.8769,  ...,  1.0978,  0.3123,  0.5783],\n",
       "         [ 0.8005,  1.8840,  1.0235,  ...,  0.2248, -0.1264, -0.7834]],\n",
       "\n",
       "        [[ 0.4884,  1.8208,  0.9184,  ...,  1.0492,  0.3033,  0.5415],\n",
       "         [ 0.9138,  1.9571,  1.1469,  ...,  0.2566, -0.0664, -0.8385]]],\n",
       "       device='cuda:0'), tensor([[[-0.3523,  0.9238,  0.3226,  ..., -0.5202,  0.2821,  0.0661],\n",
       "         [ 0.1475, -0.1097, -0.4013,  ...,  0.2435,  0.0468,  0.6080]],\n",
       "\n",
       "        [[-0.4138,  0.5849,  1.2145,  ..., -1.9029,  0.0625, -0.3666],\n",
       "         [ 0.0272,  0.2846,  0.1253,  ...,  0.8561,  0.3148, -0.9998]],\n",
       "\n",
       "        [[-0.2357,  0.9417, -0.4159,  ..., -1.2581, -0.6505,  0.2954],\n",
       "         [ 0.1399, -0.5434,  1.0082,  ...,  0.0155,  0.1105,  0.1449]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 1.2552,  1.2695,  0.7355,  ...,  0.3241,  0.3575,  0.2665],\n",
       "         [ 0.4306,  1.3417,  0.5658,  ..., -0.5008, -0.1067, -0.8843]],\n",
       "\n",
       "        [[ 1.2753,  1.2621,  0.7162,  ...,  0.2564,  0.3496,  0.2516],\n",
       "         [ 0.5099,  1.3893,  0.7150,  ..., -0.3568, -0.4306, -0.9297]],\n",
       "\n",
       "        [[ 1.2690,  1.2507,  0.7432,  ...,  0.2259,  0.3570,  0.2412],\n",
       "         [ 0.5399,  1.4743,  0.7818,  ..., -0.3328, -0.3534, -1.0008]]],\n",
       "       device='cuda:0'), tensor([[[ 1.3645e-01,  1.4392e+00,  2.5685e-01,  ...,  4.3633e-01,\n",
       "          -2.1140e-01,  6.3385e-01],\n",
       "         [-5.4326e-02, -5.5390e-01, -5.8246e-01,  ..., -4.6333e-02,\n",
       "          -2.5197e-01,  4.4997e-01]],\n",
       "\n",
       "        [[-2.6273e-01,  6.9614e-01,  1.4195e+00,  ..., -1.3937e+00,\n",
       "           4.3091e-04,  2.4836e-01],\n",
       "         [ 1.4910e-02, -5.0666e-04,  9.6748e-02,  ...,  6.6261e-01,\n",
       "           1.2701e-01, -8.9485e-01]],\n",
       "\n",
       "        [[-4.0605e-01,  5.4338e-01, -3.3603e-01,  ..., -8.4888e-01,\n",
       "          -7.2838e-01,  7.0329e-01],\n",
       "         [ 6.2258e-02, -8.7702e-01,  1.2078e+00,  ..., -1.1908e-01,\n",
       "           1.3395e-02, -2.4097e-01]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 1.8764e+00,  1.4585e+00,  1.0690e+00,  ...,  8.1245e-01,\n",
       "           1.1273e+00,  6.5720e-01],\n",
       "         [-1.3241e-01,  1.4173e+00,  1.0028e+00,  ..., -7.6990e-01,\n",
       "          -1.7148e-01, -6.3131e-01]],\n",
       "\n",
       "        [[ 1.9108e+00,  1.4738e+00,  1.0385e+00,  ...,  7.5043e-01,\n",
       "           1.1129e+00,  6.4139e-01],\n",
       "         [-1.3638e-01,  1.4393e+00,  1.0841e+00,  ..., -6.5485e-01,\n",
       "          -3.9738e-01, -7.6050e-01]],\n",
       "\n",
       "        [[ 1.8959e+00,  1.4864e+00,  1.0450e+00,  ...,  7.5851e-01,\n",
       "           1.0748e+00,  6.2117e-01],\n",
       "         [-1.4061e-01,  1.5385e+00,  1.0931e+00,  ..., -6.4300e-01,\n",
       "          -2.7876e-01, -8.7044e-01]]], device='cuda:0'), tensor([[[ 0.5148, -0.2097,  0.4796,  ...,  0.1831,  0.1582,  0.0898],\n",
       "         [-0.2514, -1.4218, -0.2708,  ...,  0.1755, -0.5437,  0.5790]],\n",
       "\n",
       "        [[-0.0316, -1.2737,  1.2422,  ..., -0.8702, -0.4823, -0.5388],\n",
       "         [-0.4470, -0.4847,  0.4200,  ...,  0.3152,  0.0051, -0.8860]],\n",
       "\n",
       "        [[-0.1184, -0.9639,  0.2105,  ..., -1.3102, -1.0305,  0.2325],\n",
       "         [ 0.3792, -0.8803,  0.8129,  ..., -0.4649, -0.4236,  0.1355]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 1.9886,  0.5590,  0.5162,  ...,  0.7909,  0.8418,  0.4308],\n",
       "         [ 0.1021,  0.7334,  0.5965,  ..., -0.8032, -0.0964, -0.5892]],\n",
       "\n",
       "        [[ 1.9908,  0.5590,  0.5206,  ...,  0.7380,  0.8099,  0.4499],\n",
       "         [ 0.1335,  0.7273,  0.6586,  ..., -0.8016, -0.2423, -0.5781]],\n",
       "\n",
       "        [[ 2.0012,  0.5371,  0.5765,  ...,  0.7183,  0.7514,  0.4595],\n",
       "         [ 0.1198,  0.8155,  0.6683,  ..., -0.8060, -0.1901, -0.6298]]],\n",
       "       device='cuda:0')), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = model(input_ids.reshape(BATCH_SIZE,1024), token_type_ids=None, attention_mask=attention_mask, labels=targets)\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ef9cd7af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(outputs[0]))\n",
    "outputs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "38bbf416",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "def train_epoch(model, data_loader, optimizer, device, scheduler, n_examples):\n",
    "    model = model.train()\n",
    "    losses = []\n",
    "    acc = 0\n",
    "    counter = 0\n",
    "  \n",
    "    for d in data_loader:\n",
    "        input_ids = d[\"input_ids\"].reshape(2,1024).to(device)\n",
    "        attention_mask = d[\"attention_mask\"].to(device)\n",
    "        targets = d[\"targets\"].to(device)\n",
    "        \n",
    "        outputs = model(input_ids=input_ids, token_type_ids=None, attention_mask=attention_mask, labels = targets)\n",
    "        loss = outputs[0]\n",
    "        logits = outputs[1]\n",
    "\n",
    "        # preds = preds.cpu().detach().numpy()\n",
    "        _, prediction = torch.max(outputs[1], dim=1)\n",
    "        targets = targets.cpu().detach().numpy()\n",
    "        prediction = prediction.cpu().detach().numpy()\n",
    "        accuracy = metrics.accuracy_score(targets, prediction)\n",
    "\n",
    "        acc += accuracy\n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        loss.backward()\n",
    "\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        counter = counter + 1\n",
    "\n",
    "    return acc / counter, np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c4a8d814",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def eval_model(model, data_loader, device, n_examples):\n",
    "    model = model.eval()\n",
    "    losses = []\n",
    "    acc = 0\n",
    "    counter = 0\n",
    "  \n",
    "    with torch.no_grad():\n",
    "        for d in data_loader:\n",
    "            #print(d[\"input_ids\"])\n",
    "            #print(d[\"input_ids\"].shape)\n",
    "            if str(d[\"input_ids\"].shape) == \"torch.Size([4, 1, 1024])\":\n",
    "                #print(\"correctSize\")\n",
    "                input_ids = d[\"input_ids\"].reshape(4,1024).to(device)\n",
    "                attention_mask = d[\"attention_mask\"].to(device)\n",
    "                targets = d[\"targets\"].to(device)\n",
    "\n",
    "                outputs = model(input_ids=input_ids, token_type_ids=None, attention_mask=attention_mask, labels = targets)\n",
    "                loss = outputs[0]\n",
    "                logits = outputs[1]\n",
    "\n",
    "                _, prediction = torch.max(outputs[1], dim=1)\n",
    "                targets = targets.cpu().detach().numpy()\n",
    "                prediction = prediction.cpu().detach().numpy()\n",
    "                accuracy = metrics.accuracy_score(targets, prediction)\n",
    "\n",
    "                acc += accuracy\n",
    "                losses.append(loss.item())\n",
    "                counter += 1\n",
    "\n",
    "    return acc / counter, np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2f7af502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "----------\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape '[2, 1024]' is invalid for input of size 1024",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[1;32m<timed exec>:8\u001b[0m\n",
      "Cell \u001b[1;32mIn [30], line 9\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[1;34m(model, data_loader, optimizer, device, scheduler, n_examples)\u001b[0m\n\u001b[0;32m      6\u001b[0m counter \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m data_loader:\n\u001b[1;32m----> 9\u001b[0m     input_ids \u001b[38;5;241m=\u001b[39m \u001b[43md\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput_ids\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1024\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     10\u001b[0m     attention_mask \u001b[38;5;241m=\u001b[39m d[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     11\u001b[0m     targets \u001b[38;5;241m=\u001b[39m d[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtargets\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: shape '[2, 1024]' is invalid for input of size 1024"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history = defaultdict(list)\n",
    "best_accuracy = 0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
    "    print('-' * 10)\n",
    "\n",
    "    train_acc, train_loss = train_epoch(\n",
    "        model,\n",
    "        train_data_loader,     \n",
    "        optimizer, \n",
    "        device, \n",
    "        scheduler, \n",
    "        len(df_train)\n",
    "    )\n",
    "\n",
    "    print(f'Train loss {train_loss} Train accuracy {train_acc}')\n",
    "\n",
    "    val_acc, val_loss = eval_model(\n",
    "        model,\n",
    "        val_data_loader, \n",
    "        device, \n",
    "        len(df_val)\n",
    "    )\n",
    "\n",
    "    print(f'Val loss {val_loss} Val accuracy {val_acc}')\n",
    "    print()\n",
    "\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "\n",
    "    if val_acc > best_accuracy:\n",
    "        torch.save(model.state_dict(), 'xlnet_model.bin')\n",
    "        best_accuracy = val_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a419afdc",
   "metadata": {},
   "source": [
    "Using the trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c05f6676",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('xlnet_model.bin'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2ef15a9d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [25], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m----> 2\u001b[0m test_acc, test_loss \u001b[38;5;241m=\u001b[39m eval_model(\n\u001b[0;32m      3\u001b[0m   model,\n\u001b[0;32m      4\u001b[0m   test_data_loader,\n\u001b[0;32m      5\u001b[0m   device,\n\u001b[0;32m      6\u001b[0m   \u001b[38;5;28mlen\u001b[39m(df_test)\n\u001b[0;32m      7\u001b[0m )\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest Accuracy :\u001b[39m\u001b[38;5;124m'\u001b[39m, test_acc)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest Loss :\u001b[39m\u001b[38;5;124m'\u001b[39m, test_loss)\n",
      "Cell \u001b[1;32mIn [22], line 30\u001b[0m, in \u001b[0;36meval_model\u001b[1;34m(model, data_loader, device, n_examples)\u001b[0m\n\u001b[0;32m     27\u001b[0m             losses\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mitem())\n\u001b[0;32m     28\u001b[0m             counter \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 30\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43macc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcounter\u001b[49m, np\u001b[38;5;241m.\u001b[39mmean(losses)\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "model = model.to(device)\n",
    "test_acc, test_loss = eval_model(\n",
    "  model,\n",
    "  test_data_loader,\n",
    "  device,\n",
    "  len(df_test)\n",
    ")\n",
    "\n",
    "print('Test Accuracy :', test_acc)\n",
    "print('Test Loss :', test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d31e6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(model, data_loader):\n",
    "    model = model.eval()\n",
    "    \n",
    "    tweets = []\n",
    "    predictions = []\n",
    "    prediction_probs = []\n",
    "    real_values = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for d in data_loader:\n",
    "\n",
    "            tweets = d[\"tweet\"]\n",
    "            input_ids = d[\"input_ids\"].reshape(4,1024).to(device)\n",
    "            attention_mask = d[\"attention_mask\"].to(device)\n",
    "            targets = d[\"targets\"].to(device)\n",
    "            \n",
    "            outputs = model(input_ids=input_ids, token_type_ids=None, attention_mask=attention_mask, labels = targets)\n",
    "\n",
    "            loss = outputs[0]\n",
    "            logits = outputs[1]\n",
    "            \n",
    "            _, preds = torch.max(outputs[1], dim=1)\n",
    "\n",
    "            probs = F.softmax(outputs[1], dim=1)\n",
    "\n",
    "            tweets.extend(tweets)\n",
    "            predictions.extend(preds)\n",
    "            prediction_probs.extend(probs)\n",
    "            real_values.extend(targets)\n",
    "\n",
    "    predictions = torch.stack(predictions).cpu()\n",
    "    prediction_probs = torch.stack(prediction_probs).cpu()\n",
    "    real_values = torch.stack(real_values).cpu()\n",
    "    return tweets, predictions, prediction_probs, real_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6809e0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tweet, y_pred, y_pred_probs, y_test = get_predictions(\n",
    "  model,\n",
    "  test_data_loader\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eccf57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred, target_names=class_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26d0d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict_sentiment(text):\n",
    "    tweet = text\n",
    "\n",
    "    encoded_tweet = tokenizer.encode_plus(\n",
    "    tweet,\n",
    "    max_length=MAX_LEN,\n",
    "    add_special_tokens=True,\n",
    "    return_token_type_ids=False,\n",
    "    pad_to_max_length=False,\n",
    "    return_attention_mask=True,\n",
    "    return_tensors='pt',\n",
    "    )\n",
    "\n",
    "    input_ids = pad_sequences(encoded_tweet['input_ids'], maxlen=MAX_LEN, dtype=torch.Tensor ,truncating=\"post\",padding=\"post\")\n",
    "    input_ids = input_ids.astype(dtype = 'int64')\n",
    "    input_ids = torch.tensor(input_ids) \n",
    "\n",
    "    attention_mask = pad_sequences(encoded_tweet['attention_mask'], maxlen=MAX_LEN, dtype=torch.Tensor ,truncating=\"post\",padding=\"post\")\n",
    "    attention_mask = attention_mask.astype(dtype = 'int64')\n",
    "    attention_mask = torch.tensor(attention_mask) \n",
    "\n",
    "    input_ids = input_ids.reshape(1,1024).to(device)\n",
    "    attention_mask = attention_mask.to(device)\n",
    "\n",
    "    outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "    outputs = outputs[0][0].cpu().detach()\n",
    "\n",
    "    probs = F.softmax(outputs, dim=-1).cpu().detach().numpy().tolist()\n",
    "    _, prediction = torch.max(outputs, dim =-1)\n",
    "\n",
    "    print(\"Positive score:\", probs[1])\n",
    "    print(\"Negative score:\", probs[0])\n",
    "    print(f'tweet: {tweet}')\n",
    "    print(f'Sentiment  : {class_names[prediction]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31550d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Bitcoin is so in right now\"\n",
    "predict_sentiment(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f1d3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading data using pandas\n",
    "path_to_data = \"Bitcoin_tweets.csv\"\n",
    "dfBitcoin = pd.read_csv(path_to_data, engine ='python')\n",
    "\n",
    "# Shuffle and Clip data\n",
    "dfBitcoin = shuffle(dfBitcoin)\n",
    "dfBitcoin = dfBitcoin[:10000]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c53c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean text. Remove tagged entities, hyperlinks, emojis\n",
    "def clean_text(text):\n",
    "    text = re.sub(r\"@[A-Za-z0-9]+\", ' ', text)\n",
    "    text = re.sub(r\"https?://[A-Za-z0-9./]+\", ' ', text)\n",
    "    text = re.sub(r\"[^a-zA-z.!?'0-9]\", ' ', text)\n",
    "    text = re.sub('\\t', ' ',  text)\n",
    "    text = re.sub(r\" +\", ' ', text)\n",
    "    return text\n",
    " \n",
    "dfBitcoin['text'] = dfBitcoin['text'].apply(clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e964f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "import time\n",
    "for text in dfBitcoin['text']:\n",
    "    if i <100 :\n",
    "        predict_sentiment(text)\n",
    "        print(\"-------------------------------------\\n\")\n",
    "        i = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d29605",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
